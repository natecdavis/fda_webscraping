{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86db0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and install necessary packages.\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63cdeb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: pandas in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: regex in /Users/nathanieldavis/opt/miniconda3/envs/spr_2022s_env/lib/python3.9/site-packages (2022.3.15)\n"
     ]
    }
   ],
   "source": [
    "install(\"bs4\")\n",
    "install(\"requests\")\n",
    "install(\"pandas\")\n",
    "install(\"regex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d92d374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86e2292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that returns a Classification Product Code (CPC) when passed an appropriately formatted HTML element.\n",
    "# Replaces some repetitious code in the scraping loop.\n",
    "def get_cpc(cpc_label):\n",
    "    cpc_element = cpc_label.parent.parent\n",
    "    cpc_code_element = cpc_element.find(\"a\")\n",
    "    cpc = cpc_code_element.text[-3:]\n",
    "    return cpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "097ad251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object from FDA Nucleic Acid Based Tests webpage.\n",
    "URL = \"https://www.fda.gov/medical-devices/in-vitro-diagnostics/nucleic-acid-based-tests\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ce8964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find table of human tests within webpage and then find all test listings as individual elements.\n",
    "human_test_table = soup.find(summary = \"List of Human Genetic Tests\")\n",
    "human_tests = human_test_table.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ee97673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a few variables based on setup of human tests table. Avoids a few magic numbers in code.\n",
    "fields_left = 0\n",
    "num_fields = 4\n",
    "trade_name_alignment = num_fields - 4\n",
    "submission_alignment = num_fields - 3\n",
    "\n",
    "# Instantiate table to hold output.\n",
    "human_tests_df = pd.DataFrame(columns = ['disease_use', 'trade_name', 'submission', 'url_of_c', 'cpc'])\n",
    "\n",
    "# Scraping loop.\n",
    "for test in human_tests:\n",
    "    \n",
    "    #Find all HTML objects associated with fields (Trade Name, Manufacturer, etc.) for a given test listing.\n",
    "    fields = test.find_all(\"td\")\n",
    "    for field in fields:\n",
    "        \n",
    "        # For each field, test to see what type of field it is with the help of field counter variable\n",
    "        # and store the field's value in the appropriate variable. \n",
    "        # Since trade name field sometimes spans many rows, we keep track of how many have passed.\n",
    "        if fields_left == 0:\n",
    "            if field.text.strip() != '':\n",
    "                disease_use = field.text.strip()\n",
    "            if field.has_attr(\"rowspan\"):\n",
    "                rowspan = int(field[\"rowspan\"])\n",
    "            else:\n",
    "                rowspan = 1\n",
    "            fields_left = rowspan * (num_fields - 1) + 1\n",
    "        elif fields_left % (num_fields - 1) == trade_name_alignment:\n",
    "            trade_name = field.text.strip()\n",
    "        elif fields_left % (num_fields - 1) == submission_alignment:\n",
    "            \n",
    "            # If field is submission field, loop through all submissions and their respective links.\n",
    "            submissions = field.find_all(\"a\")\n",
    "            for submission_element in submissions:\n",
    "                submission = submission_element.text.strip()\n",
    "                url_of_c = submission_element[\"href\"]\n",
    "                cpc = \"\"\n",
    "                \n",
    "                # Test whether submission link is broken. If so, create entry without CPC and \n",
    "                # proceed to next submission.\n",
    "                try:\n",
    "                    product_page = requests.get(url_of_c)\n",
    "                except:\n",
    "                    continue\n",
    "                else:\n",
    "                    \n",
    "                    # If submission link is not broken, create new BeautifulSoup object to scrape\n",
    "                    # using submission link URL and then scrape CPC.\n",
    "                    product_soup = BeautifulSoup(product_page.content, \"html.parser\")\n",
    "                    cpc_label = product_soup.find(string = lambda text: \"Product Code\" in text)\n",
    "                    \n",
    "                    # If there is no CPC listing on submission link page, check for additional\n",
    "                    # links to explore. Some pages require clicking down one more level before\n",
    "                    # CPC is provided.\n",
    "                    if cpc_label is None:\n",
    "                        sublinks = product_soup.find_all(style=\"text-decoration:underline;\")\n",
    "                        if sublinks is not None:\n",
    "                            for link in sublinks:\n",
    "                                sublink_url = \"https://www.accessdata.fda.gov\" + link[\"href\"]\n",
    "                                try:\n",
    "                                    sublink_page = requests.get(sublink_url)\n",
    "                                except:\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    sublink_soup = BeautifulSoup(sublink_page.content, \"html.parser\")\n",
    "                                    cpc_label = sublink_soup.find(string = lambda text: \"Product Code\" in text)\n",
    "                                    cpc = get_cpc(cpc_label)\n",
    "                                    break\n",
    "                    else:\n",
    "                        cpc = get_cpc(cpc_label)\n",
    "                finally:\n",
    "                    new_row_df = pd.DataFrame({'disease_use' : disease_use, \n",
    "                                               'trade_name' : trade_name, \n",
    "                                               'submission' : submission,\n",
    "                                               'url_of_c' : url_of_c,\n",
    "                                               'cpc' : cpc},\n",
    "                                             index = [0])\n",
    "                    human_tests_df = pd.concat([human_tests_df, new_row_df], ignore_index = True, axis = 0)\n",
    "        fields_left -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e1fd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output to CSV.\n",
    "human_tests_df.to_csv('human_tests.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
